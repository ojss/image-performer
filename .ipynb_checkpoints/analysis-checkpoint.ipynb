{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:22.261285Z",
     "start_time": "2021-04-08T17:08:22.252283Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfms\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from performer_pytorch import Performer\n",
    "from vit_pytorch.efficient import ViT\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import PIL\n",
    "import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# from fastai.learner import Learner\n",
    "# from fastai.vision.all import *\n",
    "import fastai\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:22.932537Z",
     "start_time": "2021-04-08T17:08:22.929758Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal performer network stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:23.710355Z",
     "start_time": "2021-04-08T17:08:23.694997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FCD55F477F0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = PIL.Image.open('tiny-imagenet-200/train/n01443537/images/n01443537_0.JPEG')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:24.080250Z",
     "start_time": "2021-04-08T17:08:24.075702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(img).reshape((-1, 64, 3))[:32, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:24.429137Z",
     "start_time": "2021-04-08T17:08:24.423943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:24.787017Z",
     "start_time": "2021-04-08T17:08:24.783931Z"
    }
   },
   "outputs": [],
   "source": [
    "img_net_root = Path('tiny-imagenet-200/')\n",
    "train_dir = img_net_root/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:25.245705Z",
     "start_time": "2021-04-08T17:08:25.243011Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dir = img_net_root/'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:27.428643Z",
     "start_time": "2021-04-08T17:08:27.340111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n00001930</td>\n",
       "      <td>physical entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n00002137</td>\n",
       "      <td>abstraction, abstract entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n00002452</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00002684</td>\n",
       "      <td>object, physical object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                             1\n",
       "0  n00001740                        entity\n",
       "1  n00001930               physical entity\n",
       "2  n00002137  abstraction, abstract entity\n",
       "3  n00002452                         thing\n",
       "4  n00002684       object, physical object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clss_df = pd.read_csv('tiny-imagenet-200/words.txt', delimiter='\\t', header=None)\n",
    "clss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:31.794149Z",
     "start_time": "2021-04-08T17:08:27.819955Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_tmp = datasets.ImageFolder(train_dir, transform=tfms.Compose([#tfms.Resize((32, 32)),\n",
    "    tfms.ToTensor(), tfms.Lambda(lambda x: torch.flatten(x).unsqueeze(0))\n",
    "]))\n",
    "train_loader_tmp = data.DataLoader(train_dataset_tmp, batch_size=48, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:33.908743Z",
     "start_time": "2021-04-08T17:08:32.840643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 1, 12288])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_loader_tmp))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:08:35.408152Z",
     "start_time": "2021-04-08T17:08:35.201454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=64 * 64 * 3, out_features=512),\n",
    "    Performer(dim=512, depth=6, heads=8, causal=True),\n",
    "    nn.Linear(in_features=512, out_features=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0062, 0.0090, 0.0044, 0.0015, 0.0035, 0.0028, 0.0027, 0.0019, 0.0043,\n",
       "         0.0019, 0.0030, 0.0106, 0.0030, 0.0056, 0.0074, 0.0027, 0.0049, 0.0049,\n",
       "         0.0029, 0.0047, 0.0029, 0.0057, 0.0036, 0.0141, 0.0023, 0.0051, 0.0062,\n",
       "         0.0020, 0.0034, 0.0053, 0.0070, 0.0018, 0.0093, 0.0040, 0.0140, 0.0027,\n",
       "         0.0084, 0.0021, 0.0044, 0.0012, 0.0019, 0.0024, 0.0028, 0.0046, 0.0080,\n",
       "         0.0092, 0.0021, 0.0127, 0.0048, 0.0067, 0.0068, 0.0036, 0.0143, 0.0072,\n",
       "         0.0030, 0.0093, 0.0047, 0.0056, 0.0022, 0.0029, 0.0031, 0.0062, 0.0105,\n",
       "         0.0057, 0.0067, 0.0029, 0.0030, 0.0027, 0.0076, 0.0068, 0.0049, 0.0071,\n",
       "         0.0043, 0.0027, 0.0064, 0.0150, 0.0085, 0.0028, 0.0067, 0.0076, 0.0073,\n",
       "         0.0038, 0.0026, 0.0045, 0.0068, 0.0046, 0.0057, 0.0078, 0.0015, 0.0110,\n",
       "         0.0047, 0.0046, 0.0028, 0.0020, 0.0057, 0.0073, 0.0038, 0.0018, 0.0032,\n",
       "         0.0052, 0.0073, 0.0023, 0.0026, 0.0043, 0.0068, 0.0017, 0.0059, 0.0068,\n",
       "         0.0077, 0.0039, 0.0037, 0.0079, 0.0025, 0.0018, 0.0029, 0.0036, 0.0018,\n",
       "         0.0032, 0.0053, 0.0040, 0.0114, 0.0028, 0.0053, 0.0012, 0.0065, 0.0096,\n",
       "         0.0029, 0.0039, 0.0067, 0.0029, 0.0076, 0.0095, 0.0062, 0.0115, 0.0067,\n",
       "         0.0063, 0.0047, 0.0048, 0.0053, 0.0021, 0.0029, 0.0029, 0.0028, 0.0056,\n",
       "         0.0040, 0.0036, 0.0042, 0.0018, 0.0051, 0.0058, 0.0020, 0.0067, 0.0106,\n",
       "         0.0047, 0.0059, 0.0031, 0.0050, 0.0062, 0.0050, 0.0056, 0.0058, 0.0032,\n",
       "         0.0039, 0.0062, 0.0046, 0.0033, 0.0035, 0.0036, 0.0025, 0.0035, 0.0037,\n",
       "         0.0047, 0.0056, 0.0035, 0.0039, 0.0047, 0.0023, 0.0019, 0.0013, 0.0044,\n",
       "         0.0126, 0.0027, 0.0048, 0.0044, 0.0069, 0.0131, 0.0043, 0.0043, 0.0017,\n",
       "         0.0040, 0.0033, 0.0014, 0.0061, 0.0072, 0.0034, 0.0041, 0.0058, 0.0039,\n",
       "         0.0041, 0.0019]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(xb)[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:09:02.164993Z",
     "start_time": "2021-04-08T17:08:58.141699Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(train_dir, transform=tfms.Compose([#tfms.Resize((32, 32)),\n",
    "    tfms.ToTensor(), #tfms.Lambda(lambda x: torch.flatten(x).reshape(24, 512))\n",
    "]))\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=48, shuffle=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=tfms.Compose([#tfms.Resize((32, 32)),\n",
    "    tfms.ToTensor(), #tfms.Lambda(lambda x: torch.flatten(x))\n",
    "]))\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=64//4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12288])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][0].reshape(1, 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 3, 64, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Performer(dim=512, depth=6, heads=8, causal=True),\n",
    "    nn.Conv1d(in_channels=24, out_channels=1, kernel_size=1),\n",
    "    nn.Linear(in_features=512, out_features=200),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[512], expected input with shape [*, 512], but got input of size[48, 3, 64, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d46fef46cd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_check_redraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_redraw_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPerformerLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/performer_pytorch/reversible.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers_and_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mg_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    170\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2092\u001b[0m             return handle_torch_function(\n\u001b[1;32m   2093\u001b[0m                 layer_norm, (input,), input, normalized_shape, weight=weight, bias=bias, eps=eps)\n\u001b[0;32m-> 2094\u001b[0;31m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0m\u001b[1;32m   2095\u001b[0m                             torch.backends.cudnn.enabled)\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[512], expected input with shape [*, 512], but got input of size[48, 3, 64, 64]"
     ]
    }
   ],
   "source": [
    "model(xb.to(device))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:09:48.551787Z",
     "start_time": "2021-04-08T17:09:48.419466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n"
     ]
    }
   ],
   "source": [
    "performer = Performer(dim=512, depth=6, heads=8, causal=True)\n",
    "v = ViT(dim=512, image_size=64, patch_size=4, num_classes=200, transformer=performer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n",
       "    (1): Linear(in_features=48, out_features=512, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.transformer = performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT(\n",
      "  (to_patch_embedding): Sequential(\n",
      "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n",
      "    (1): Linear(in_features=48, out_features=512, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (transformer): Performer(\n",
      "    (net): SequentialSequence(\n",
      "      (layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): SelfAttention(\n",
      "              (fast_attention): FastAttention(\n",
      "                (kernel_fn): ReLU()\n",
      "              )\n",
      "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): Chunk(\n",
      "              (fn): FeedForward(\n",
      "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): SelfAttention(\n",
      "              (fast_attention): FastAttention(\n",
      "                (kernel_fn): ReLU()\n",
      "              )\n",
      "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): Chunk(\n",
      "              (fn): FeedForward(\n",
      "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): SelfAttention(\n",
      "              (fast_attention): FastAttention(\n",
      "                (kernel_fn): ReLU()\n",
      "              )\n",
      "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): Chunk(\n",
      "              (fn): FeedForward(\n",
      "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): SelfAttention(\n",
      "              (fast_attention): FastAttention(\n",
      "                (kernel_fn): ReLU()\n",
      "              )\n",
      "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): Chunk(\n",
      "              (fn): FeedForward(\n",
      "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): ModuleList(\n",
      "          (0): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): SelfAttention(\n",
      "              (fast_attention): FastAttention(\n",
      "                (kernel_fn): ReLU()\n",
      "              )\n",
      "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): Chunk(\n",
      "              (fn): FeedForward(\n",
      "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): ModuleList(\n",
      "          (0): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): SelfAttention(\n",
      "              (fast_attention): FastAttention(\n",
      "                (kernel_fn): ReLU()\n",
      "              )\n",
      "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): PreLayerNorm(\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fn): Chunk(\n",
      "              (fn): FeedForward(\n",
      "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_latent): Identity()\n",
      "  (mlp_head): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=200, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ojass/anaconda3/envs/ai/lib/python3.8/site-packages/torch/cuda/memory.py:231: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(v.parameters(), lr=lr, weight_decay=1e-7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "v = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_small_trainset = data.Subset(train_dataset, torch.arange(10000))\n",
    "v_small_train_loader = data.DataLoader(v_small_trainset, batch_size=48, shuffle=True)\n",
    "\n",
    "v_small_valtrainset = data.Subset(val_dataset, torch.arange(100))\n",
    "v_small_val_loader = data.DataLoader(v_small_valtrainset, batch_size=48//4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 3.4100: 100%|██████████| 209/209 [05:04<00:00,  1.46s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1bc7de8150dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mepoch_val_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mepoch_val_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    total_loss = 0 \n",
    "    train_cnt = 0\n",
    "    pbar = tqdm.tqdm(v_small_train_loader)\n",
    "    for data, label in pbar:\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        with amp.autocast(enabled=True):\n",
    "            output = v(data)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad()\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "        total_loss += loss.item() * data.shape[0]\n",
    "        train_cnt += data.shape[0]\n",
    "        pbar.set_description(f\"Loss : {total_loss/train_cnt:.4f}\")\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in v_small_val_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = v(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(v_small_val_loader)\n",
    "            epoch_val_loss += val_loss / len(v_small_val_loader)\n",
    "    scheduler.step()\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 : Average loss : -5.9279, test_acc : 0.0000\n"
     ]
    }
   ],
   "source": [
    "v.eval()\n",
    "for xb ,yb in val_loader:\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "    y_pred = v(xb)\n",
    "    y_argmax = y_pred.argmax(dim=1)\n",
    "    acc += (yb == y_argmax).sum()\n",
    "    val_cnt += xb.shape[0]\n",
    "\n",
    "print(f'epoch {epoch} : Average loss : {total_loss/train_cnt:.4f}, test_acc : {acc.item()/val_cnt:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_ncwh = xb.permute(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 192, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb_ncwh.contiguous().view(N, C * W, H).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ViP Stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(train_dir, transform=tfms.Compose([#tfms.Resize((32, 32)),\n",
    "    tfms.ToTensor(), #tfms.Lambda(lambda x: torch.flatten(x).reshape(24, 512))\n",
    "]))\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=tfms.Compose([#tfms.Resize((32, 32)),\n",
    "    tfms.ToTensor(), #tfms.Lambda(lambda x: torch.flatten(x))\n",
    "]))\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=64//4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 32, 16, 16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = nn.Sequential(\n",
    "    nn.Conv2d(3, 128, kernel_size=3, stride=2),\n",
    "    nn.Conv2d(128, 32, kernel_size=1, stride=2)\n",
    ")\n",
    "xbt = tmp(xb)\n",
    "N, C, H, W  = xbt.shape\n",
    "(N, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbt.permute(0, 1, 3, 2)\n",
    "xbt.contiguous().view(N, C * W, H).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from smallest_working_performer.model import ViP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(3, 1, kernel_size=(1), stride=1)(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(\n",
    "    nn.Conv2d(3, 1, 1, stride=1),\n",
    "    ViP(\n",
    "        image_pix=64,\n",
    "        class_cnt=200,\n",
    "        layer_cnt=6\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): ViP(\n",
       "    (uf): Unfold(kernel_size=[4, 4], dilation=1, padding=0, stride=[4, 4])\n",
       "    (dp): Dropout(p=0.1, inplace=False)\n",
       "    (head): Linear(in_features=512, out_features=200, bias=True)\n",
       "    (patch_emb): Linear(in_features=16, out_features=512, bias=True)\n",
       "    (mains): Sequential(\n",
       "      (0): performer_attn_block(\n",
       "        (kqv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): performer_attn_block(\n",
       "        (kqv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): performer_attn_block(\n",
       "        (kqv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): performer_attn_block(\n",
       "        (kqv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): performer_attn_block(\n",
       "        (kqv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): performer_attn_block(\n",
       "        (kqv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4019, -0.3193,  0.1937,  ...,  0.0795,  0.2869,  0.2534],\n",
       "        [-0.1872, -0.0691, -0.0475,  ...,  0.0340, -0.0061,  0.3819],\n",
       "        [-0.1539, -0.0254,  0.2474,  ...,  0.0730, -0.0199,  0.4502],\n",
       "        ...,\n",
       "        [-0.4216, -0.1328,  0.0548,  ...,  0.4197,  0.3043,  0.2659],\n",
       "        [-0.2275,  0.2330, -0.1131,  ...,  0.2327,  0.0469,  0.3041],\n",
       "        [-0.2039, -0.3364,  0.0313,  ...,  0.4046,  0.2198,  0.3717]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(model2.parameters(), lr=2e-5, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 5.1329: 100%|██████████| 1563/1563 [12:50<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 : Average loss : 5.1329, test_acc : 0.0067\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    acc = 0\n",
    "    total_loss = 0 \n",
    "    train_cnt = 0\n",
    "    val_cnt = 0\n",
    "    model2.train()\n",
    "    pbar = tqdm.tqdm(train_loader)\n",
    "    for xb, yb in pbar:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        \n",
    "        y_pred = model2(xb)  \n",
    "        opt.zero_grad()\n",
    "        loss_val = loss(y_pred, yb)\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss_val.item() * xb.shape[0]\n",
    "        train_cnt += xb.shape[0]\n",
    "        pbar.set_description(f\"Loss : {total_loss/train_cnt:.4f}\")\n",
    "        \n",
    "    model.eval()\n",
    "    for xb ,yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        y_pred = model2(xb)\n",
    "        y_argmax = y_pred.argmax(dim=1)\n",
    "        acc += (yb == y_argmax).sum()\n",
    "        val_cnt += xb.shape[0]\n",
    "    \n",
    "    print(f'epoch {epoch} : Average loss : {total_loss/train_cnt:.4f}, test_acc : {acc.item()/val_cnt:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
